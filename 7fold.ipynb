{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b1d70f-c232-49c8-a3d1-56759fe14f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ceb17e9-2f7b-4cd6-994e-12d9d6bedbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for data and separate test set\n",
    "data_path = 'C:\\\\Users\\\\HP\\\\anaconda3\\\\envs\\\\Heather\\\\signsss'\n",
    "test_path = 'C:\\\\Users\\\\HP\\\\Desktop\\\\ane\\\\Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc345a4c-2699-4165-82bb-c8742cd2e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FrameDataset class (as you have already defined it)\n",
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(os.listdir(folder_path))}\n",
    "        \n",
    "        for label_folder in os.listdir(folder_path):\n",
    "            label_path = os.path.join(folder_path, label_folder)\n",
    "            if os.path.isdir(label_path):\n",
    "                for frame in os.listdir(label_path):\n",
    "                    frame_path = os.path.join(label_path, frame)\n",
    "                    self.data.append((frame_path, self.label_to_idx[label_folder]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_path, label_idx = self.data[idx]\n",
    "        image = Image.open(frame_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d13ade-f962-4c32-92a8-d871fe92e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e7e0e79-9b8a-4cf5-9cb2-e885a5e8c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "full_dataset = FrameDataset(data_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8b8f53-d678-4006-beeb-a405d367c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and training function\n",
    "def initialize_model(num_classes):\n",
    "    model = models.resnet50(weights='DEFAULT')\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, epochs, criterion, optimizer, device):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, \"\n",
    "              f\"Train Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "              f\"Val Loss: {val_loss / len(val_loader):.4f}, \"\n",
    "              f\"Val Acc: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b806294-9844-4ee0-9132-a4d4605042e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 10  # Or any number you find suitable\n",
    "num_classes = len(os.listdir(data_path))\n",
    "fold_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b7935e-c91a-4a0d-a0d3-1bcc214630d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=2 greater than the number of samples: n_samples=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 7-Fold Cross Validation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(full_dataset)):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Create data loaders for the current fold\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Heather\\lib\\site-packages\\sklearn\\model_selection\\_split.py:409\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    407\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         (\n\u001b[0;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    414\u001b[0m     )\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=2 greater than the number of samples: n_samples=0."
     ]
    }
   ],
   "source": [
    "# 7-Fold Cross Validation\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "    \n",
    "    # Create data loaders for the current fold\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize model, criterion, and optimizer for each fold\n",
    "    model = initialize_model(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    # Train and validate\n",
    "    train_and_validate(model, train_loader, val_loader, epochs, criterion, optimizer, device)\n",
    "\n",
    "    # Evaluate fold accuracy\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    fold_accuracy = 100 * correct / total\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Fold {fold + 1} Validation Accuracy: {fold_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1cdb09-b375-4f97-83d1-cf388d709bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average cross-validation accuracy\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"\\nAverage Cross-Validation Accuracy: {average_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc4a1b-6263-4de1-8f05-4ddb6131be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the final model on the separate test set (if applicable)\n",
    "# Save the model if needed\n",
    "torch.save(model.state_dict(), 'Tsakatsa_CrossVal.pth')\n",
    "print(\"Model Saved Successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Heather)",
   "language": "python",
   "name": "heather"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
